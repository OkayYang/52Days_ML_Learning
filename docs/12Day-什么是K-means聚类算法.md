
# 12Day-什么是K-means聚类算法
机器学习算法主要分为两大类：**有监督学习和无监督学习**，它们的核心思想不同。


有监督学习，主要是在已经有“标签”的数据集上构建机器学习模型，这些标签就像“答案”一样。但在实际生产环境中，大部分数据是没有标签的。贴上这些标签需要大量人力，尤其是在数据量巨大或者难以获取参考答案的情况下，标记数据是非常困难的，而且标记速度通常远远慢于数据生成速度。因此，当我们需要对没有标签的数据进行分类时，无监督学习算法就派上了用场。

常见的无监督学习算法包括K-means聚类算法、均值漂移聚类算法、主成分分析法（即PCA算法）、期望最大化算法（EM算法）等。本节将重点介绍最经典的无监督学习算法之一，即K-means算法。它属于聚类算法的一种，也是最为经典的聚类算法之一。K-means算法原理简单，易于理解，因此在各种领域得到广泛应用。通过学习K-means算法，您将了解什么是聚类问题以及如何解决它。

## 聚类和分类的区别
聚类和分类是两种不同的数据分析方法，它们有以下主要区别：

1. **监督学习 vs. 无监督学习**:
    - **分类**是一种监督学习方法，其中算法根据预先标记的训练数据来学习，以预测新数据点的类别。分类问题已经有标签的数据，模型的目标是学习如何将数据点映射到已知类别中的一个。
    - **聚类**是一种无监督学习方法，其中算法处理未标记的数据，并尝试将数据点分组成具有相似特征的簇。在聚类中，没有预定义的类别，模型的目标是发现数据中的内在结构或模式。

2. **目的**:
    - **分类**的目的是将数据点分配到预定义的类别中，以便进行预测或决策。通常，分类的输出是明确的类别标签。
    - **聚类**的目的是探索数据中的相似性和结构，而不是为数据点指定明确的类别标签。聚类的输出是将数据点分组为簇，但这些簇的含义可能需要进一步解释。

3. **训练数据**:
    - 在**分类**中，训练数据通常包括带有已知类别标签的样本，以便模型可以学习如何分类新数据点。
    - 在**聚类**中，训练数据不包括类别标签，只包括数据本身。模型根据数据的相似性来执行聚类操作。

4. **应用领域**:
    - **分类**通常应用于需要预测类别或标签的任务，如垃圾邮件过滤、图像识别、文本分类等。
    - **聚类**通常应用于数据探索、市场细分、模式检测、异常检测等任务。

## 找相似

当我们聊到“找相似”，我们通常提到“物以类聚，人以群分”的概念。这句话意味着人们倾向于与兴趣相投的人互相聚集，而相似的事物也会自然地聚在一起。在数据集中，具有相似特征的数据也应该被聚集在一起，这有助于更容易地区分它们。但是，在现实世界中，很少有两片叶子完全相同，因此在进行分类时，聚类算法只能尽量找到相似之处。如果两个数据点共享更多相似特征，那么它们更有可能属于同一类别；相反，如果它们之间的不同特征更多，那么它们可能不属于同一类别。

想象一下，动物种类可以按照科属来划分，比如豹、老虎和猫都属于猫科动物。虽然很难相信，温顺的家猫和凶猛的老虎属于同一科，但这表明它们有一些相似之处，例如擅长攀爬和跳跃、柔软的皮毛、锋利的爪子等等。科学家最初也没有明确的答案来定义“猫科动物”，但通过寻找相似特征，他们最终将这些动物分为不同的类别。这个过程也可以被视为“无监督学习”。

在无监督学习中，解决聚类问题的关键在于“找相似”。接下来，我们将介绍 K-means 聚类算法，了解它如何在数据集中查找相似性。

## 什么是簇
在聚类问题中，有一个重要的概念叫做“簇”（Cluster）。在聚类算法的帮助下，数据集中的样本数据最终会被聚集成一些“类”，这些类在机器学习中通常被称为“簇”。请注意，这只适用于使用聚类算法的情况，因此“簇”是解决聚类问题的表现形式，数据集中的数据样本最终会以“簇”的形式进行分类。然而，在解决聚类问题时，通常没有确定要形成多少个簇的标准，因为没有参考答案。

举个简单的例子：有3个相同大小的正方形和3个相同大小的圆形，每个方形和圆形都有不同的颜色，分别是黄色、红色和绿色。如果我们按形状分类，可以将它们分为两个簇，即圆形和正方形。如果按颜色分类，可以分为三个簇，即黄色、红色和绿色。由此可见，选择分簇的条件不同，形成的簇数量也不同，这将影响聚类的结果。

不同的聚类算法采用不同的方法，主要分为划分法、层次法、密度法和网格法。这些方法大致可以总结为两类：一类是需要预先设定簇的数量，另一类则是在聚类过程中自动形成。

## 理解K的含义
K-means是一种采用划分法的聚类算法。K-means算法与前面提到的KNN分类算法一样，都包含字母“K”。在机器学习中，通常使用字母“K”来表示“多”，就像数学中使用字母“n”表示一样。但在K-means算法中，K的含义是什么呢？

与KNN分类算法不同，K-means算法没有一个明确的参考标准。如果不限制K的值，K-means可能会形成任意数量的“簇”。因此，我们需要预先设定“簇”的数量。K-means中的K表示最终要形成多少个“簇”，或者说要将数据分为多少个“类”。

## 如何量化“相似”
在解决聚类问题时，关键是要找到相似之处。只有找到相同点，才能实现类别的划分。在聚类过程中，我们尝试让相似的样本点彼此靠近，就像朋友聚集在一起一样。这个过程看起来很简单，但实际上需要采取特定的操作和标准来衡量“相似”。

“相似”也称为“相似度”，与之相反的是“相异度”。这些词汇用于衡量对象之间的相似程度。

在K-means聚类算法中，我们需要一个“中心点”作为参考点，然后根据距离来确定与这个中心点最接近的数据点。这个中心点被称为“质心”。不同的数据点归属于不同的质心，从而形成不同的簇。

下面是K-means算法的主要工作流程：

1. **随机选择质心**：开始时，随机选择K个数据点作为初始质心。

2. **分配数据点**：对于每个数据点，计算它与每个质心的距离，将其分配到距离最近的簇中。

3. **计算新质心**：对每个簇中的数据点，计算它们的均值，以得到新的质心坐标。

4. **迭代**：重复执行第2和第3步，直到质心不再发生显著的变化，或者达到预定的迭代次数。

5. **得到最终簇**：最终，数据点被划分为K个簇，每个簇以其质心为中心。

通过这一过程，K-means算法找到了数据中的共同点，将相似的数据点聚合在一起，完成了聚类任务。

## K-means聚类算法的示例
以下是一个K-means聚类算法的示例，其中我们尝试聚类12个数据点成3个簇。这个示例演示了K-means的工作流程，包括质心的初始化、数据点的分配、新质心的计算以及最终的簇分配。

| 数据点 | x 坐标 | y 坐标 |
|--------|---------|---------|
| 数据点1 | 2       | 3       |
| 数据点2 | 2       | 4       |
| 数据点3 | 3       | 2       |
| 数据点4 | 4       | 3       |
| 数据点5 | 9       | 10      |
| 数据点6 | 8       | 10      |
| 数据点7 | 10      | 9       |
| 数据点8 | 10      | 8       |
| 数据点9 | 15      | 2       |
| 数据点10 | 16      | 3       |
| 数据点11 | 14      | 3       |
| 数据点12 | 15      | 4       |

### 步骤1：随机选择质心

在初始阶段，我们随机选择3个数据点作为初始质心：

| 初始质心 | x 坐标 | y 坐标 |
|-----------|---------|---------|
| 质心1     | 4       | 3       |
| 质心2     | 10      | 9       |
| 质心3     | 14.5    | 3.25    |

### 步骤2：分配数据点

然后，我们计算每个数据点到这3个初始质心的距离，并将它们分配到最近的簇：

| 数据点 | 最近质心 | 簇 |
|--------|------------|---|
| 数据点1 | 质心1     | 1 |
| 数据点2 | 质心1     | 1 |
| 数据点3 | 质心1     | 1 |
| 数据点4 | 质心1     | 1 |
| 数据点5 | 质心2     | 2 |
| 数据点6 | 质心2     | 2 |
| 数据点7 | 质心2     | 2 |
| 数据点8 | 质心2     | 2 |
| 数据点9 | 质心3     | 3 |
| 数据点10 | 质心3     | 3 |
| 数据点11 | 质心3     | 3 |
| 数据点12 | 质心3     | 3 |

### 步骤3：计算新质心

接下来，我们计算每个簇中所有数据点的均值，以获得新的质心坐标：

| 簇 | 新质心 | 新质心坐标 |
|----|--------|--------------|
| 1  | 质心1 | (2.75, 3)   |
| 2  | 质心2 | (9.5, 9.25) |
| 3  | 质心3 | (15, 3.25)  |

### 步骤4：迭代

重复步骤2和步骤3，直到质心不再发生显著变化或达到指定的迭代次数。在每次迭代中，数据点将重新分配到最近的质心，并重新计算质心坐标。

### 步骤5：得到最终簇

最终，数据点被划分为3个簇，每个簇以其质心为中心。这是K-means聚类算法的结果，数据点按簇进行了分类。



